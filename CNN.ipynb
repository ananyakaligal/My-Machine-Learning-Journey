{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkyisrwJMczSOjzZePZaM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananyakaligal/My-Machine-Learning-Journey/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAGB2vmrsW03",
        "outputId": "ec8f1729-9b00-49ea-d3ae-5a91ba588bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "import time"
      ],
      "metadata": {
        "id": "1FMnH3N4sl0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "batchSize = 256\n",
        "numEpochs = 15"
      ],
      "metadata": {
        "id": "J125YTLisnnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist(train_samples=None, test_samples=None):\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Normalize the pixel values to be between 0 and 1\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "    # Reshape to add the channel dimension\n",
        "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "    y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "\n",
        "    if train_samples:\n",
        "        # Randomly sample the training data\n",
        "        indices_train = np.random.choice(len(x_train), train_samples, replace=False)\n",
        "        x_train = x_train[indices_train]\n",
        "        y_train = y_train[indices_train]\n",
        "\n",
        "    if test_samples:\n",
        "        # Randomly sample the testing data\n",
        "        indices_test = np.random.choice(len(x_test), test_samples, replace=False)\n",
        "        x_test = x_test[indices_test]\n",
        "        y_test = y_test[indices_test]\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "# Example usage: Load 1000 training samples and 200 test samples\n",
        "x_train, y_train, x_test, y_test = load_mnist(train_samples=10000, test_samples=2000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icOGiAfmspZn",
        "outputId": "d0306320-3d29-44d6-ac0e-342a7c148992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shapes of the datasets\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgqKeAr7suAD",
        "outputId": "b36815b7-b65a-49d7-a431-8cdf27925d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (10000, 28, 28, 1)\n",
            "y_train shape: (10000, 10)\n",
            "x_test shape: (2000, 28, 28, 1)\n",
            "y_test shape: (2000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def format_data(data):\n",
        "    indices = []\n",
        "    values = []\n",
        "    batch_size = data.shape[0]\n",
        "    height = data.shape[1]\n",
        "    width = data.shape[2]\n",
        "    channels = data.shape[3] if len(data.shape) > 3 else 1  # Add channel dimension if present\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        for row in range(height):\n",
        "            for col in range(width):\n",
        "                for channel in range(channels):\n",
        "                    indices.append([i + 1, row + 1, col + 1, channel + 1])  # Adjust indices to start from 1\n",
        "                    values.append(float(data[i, row, col, channel]))\n",
        "\n",
        "    return np.array(indices), np.array(values)\n"
      ],
      "metadata": {
        "id": "9sAU-r5-szir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Formatting data\n",
        "formatted_x_train_indices, formatted_x_train_values = format_data(x_train)\n",
        "formatted_x_test_indices, formatted_x_test_values = format_data(x_test)"
      ],
      "metadata": {
        "id": "S-iHx0r4tJiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to print samples of the formatted data\n",
        "def print_sample(indices, values, sample_size=30):\n",
        "    for i in range(sample_size):\n",
        "        print(f\"Indices: {indices[i]}, Value: {values[i]}\")\n",
        "\n",
        "# Print samples\n",
        "print(\"Sample of train_indices and train_values:\")\n",
        "print_sample(formatted_x_train_indices, formatted_x_train_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ytZbOmetLDT",
        "outputId": "095bd13f-dd8c-467b-dd5c-5e24ea701ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of train_indices and train_values:\n",
            "Indices: [1 1 1 1], Value: 0.0\n",
            "Indices: [1 1 2 1], Value: 0.0\n",
            "Indices: [1 1 3 1], Value: 0.0\n",
            "Indices: [1 1 4 1], Value: 0.0\n",
            "Indices: [1 1 5 1], Value: 0.0\n",
            "Indices: [1 1 6 1], Value: 0.0\n",
            "Indices: [1 1 7 1], Value: 0.0\n",
            "Indices: [1 1 8 1], Value: 0.0\n",
            "Indices: [1 1 9 1], Value: 0.0\n",
            "Indices: [ 1  1 10  1], Value: 0.0\n",
            "Indices: [ 1  1 11  1], Value: 0.0\n",
            "Indices: [ 1  1 12  1], Value: 0.0\n",
            "Indices: [ 1  1 13  1], Value: 0.0\n",
            "Indices: [ 1  1 14  1], Value: 0.0\n",
            "Indices: [ 1  1 15  1], Value: 0.0\n",
            "Indices: [ 1  1 16  1], Value: 0.0\n",
            "Indices: [ 1  1 17  1], Value: 0.0\n",
            "Indices: [ 1  1 18  1], Value: 0.0\n",
            "Indices: [ 1  1 19  1], Value: 0.0\n",
            "Indices: [ 1  1 20  1], Value: 0.0\n",
            "Indices: [ 1  1 21  1], Value: 0.0\n",
            "Indices: [ 1  1 22  1], Value: 0.0\n",
            "Indices: [ 1  1 23  1], Value: 0.0\n",
            "Indices: [ 1  1 24  1], Value: 0.0\n",
            "Indices: [ 1  1 25  1], Value: 0.0\n",
            "Indices: [ 1  1 26  1], Value: 0.0\n",
            "Indices: [ 1  1 27  1], Value: 0.0\n",
            "Indices: [ 1  1 28  1], Value: 0.0\n",
            "Indices: [1 2 1 1], Value: 0.0\n",
            "Indices: [1 2 2 1], Value: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tensor_from_data(indices, values, shape):\n",
        "    # Convert indices and values to tensors\n",
        "    indices_tensor = tf.constant(indices, dtype=tf.int64)\n",
        "    values_tensor = tf.constant(values, dtype=tf.float32)\n",
        "\n",
        "    # Create sparse tensor\n",
        "    sparse_tensor = tf.sparse.SparseTensor(\n",
        "        indices=indices_tensor,\n",
        "        values=values_tensor,\n",
        "        dense_shape=shape\n",
        "    )\n",
        "\n",
        "    # Convert sparse tensor to dense tensor\n",
        "    dense_tensor = tf.sparse.to_dense(sparse_tensor)\n",
        "    return dense_tensor"
      ],
      "metadata": {
        "id": "iuCvdfiCtN72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PZNfWyPLt0AV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}